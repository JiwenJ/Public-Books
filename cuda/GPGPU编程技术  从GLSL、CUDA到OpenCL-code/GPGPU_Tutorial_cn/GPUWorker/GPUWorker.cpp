/*
Highly Optimized Object-Oriented Molecular Dynamics (HOOMD) Open
Source Software License
Copyright (c) 2008 Ames Laboratory Iowa State University
All rights reserved.

Redistribution and use of HOOMD, in source and binary forms, with or
without modification, are permitted, provided that the following
conditions are met:

* Redistributions of source code must retain the above copyright notice,
this list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the distribution.

* Neither the name of the copyright holder nor the names HOOMD's
contributors may be used to endorse or promote products derived from this
software without specific prior written permission.

Disclaimer

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDER AND
CONTRIBUTORS ``AS IS''  AND ANY EXPRESS OR IMPLIED WARRANTIES,
INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY
AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.

IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS  BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
THE POSSIBILITY OF SUCH DAMAGE.
*/

// $Id$
// $URL$

/*! \file GPUWorker.cc
	\brief Code the GPUWorker class
*/

//#ifdef USE_CUDA

#include <boost/bind.hpp>
#include <string>
#include <sstream>
#include <iostream>

#include "GPUWorker.h"

using namespace boost;
using namespace std;

/*! \param dev GPU device number to be passed to cudaSetDevice()

	Constructing a GPUWorker creates the worker thread and immeadiately assigns it to
	a device with cudaSetDevice().
*/
GPUWorker::GPUWorker(int dev) : m_exit(false), m_work_to_do(false), m_last_error(cudaSuccess)
	{
	m_thread.reset(new thread(bind(&GPUWorker::performWorkLoop, this)));
	call(bind(cudaSetDevice, dev));
	}

/*! Shuts down the worker thread
*/
GPUWorker::~GPUWorker()
	{
	// set the exit condition
		{
		mutex::scoped_lock lock(m_mutex);
		m_work_to_do = true;
		m_exit = true;
		}

	// notify the thread there is work to do
	m_cond_work_to_do.notify_one();

	// join with the thread
	m_thread->join();
	}


/*! \param func Function call to execute in the worker thread

	call() executes a CUDA call to in a worker thread. Any function
	with any arguments can be passed in to be queued using boost::bind.
	Examples:
\code
gpu.call(bind(function, arg1, arg2, arg3, ...));
gpu.call(bind(cudaMemcpy, &h_float, d_float, sizeof(float), cudaMemcpyDeviceToHost));
gpu.call(bind(cudaThreadSynchronize));
\endcode
	The only requirement is that the function returns a cudaError_t. Since every
	single CUDA Runtime API function does so, you can call any Runtime API function.
	You can call any custom functions too, as long as you return a cudaError_t representing
	the error of any CUDA functions called within. This is typical in kernel
	driver functions. For example, a .cu file might contain:
\code
__global__ void kernel() { ... }
cudaError_t kernel_driver()
	{
	kernel<<<blocks, threads>>>();
	#ifdef NDEBUG
	return cudaSuccess;
	#else
	cudaThreadSynchronize();
	return cudaGetLastError();
	#endif
	}
\endcode
	It is recommended to just return cudaSuccess in release builds to keep the asynchronous
	call stream going with no cudaThreadSynchronize() overheads.

	call() ensures that \a func has been executed before it returns. This is
	desired behavior, most of the time. For calling kernels or other asynchronous
	CUDA functions, use callAsync(), but read the warnings in it's documentation
	carefully and understand what you are doing. Why have callAsync() at all?
	The original purpose for designing GPUWorker is to allow execution on
	multiple GPUs simultaneously which can only be done with asynchronous calls.

	An exception will be thrown if the CUDA call returns anything other than
	cudaSuccess.
*/
void GPUWorker::call(const boost::function< cudaError_t (void) > &func)
	{
	// this mutex lock is to prevent multiple threads from making
	// simultaneous calls. Thus, they can depend on the exception
	// thrown to exactly be the error from their call and not some
	// race condition from another thread
	// making GPUWorker calls to a single GPUWorker from multiple threads
	// still isn't supported
	mutex::scoped_lock lock(m_call_mutex);

	// call and then sync
	callAsync(func);
	sync();
	}

/*! \param func Function to execute inside the worker thread

	callAsync is like call(), but  returns immeadiately after entering \a func into the queue.
	The worker thread will eventually get around to running it. Multiple contiguous
	calls to callAsync() will result in potentially many function calls
	being queued before any run.

	\warning There are many potential race conditions when using callAsync().
	For instance, consider the following calls:
	\code
gpu.callAsync(bind(cudaMalloc(&d_array, n_bytes)));
gpu.callAsync(bind(cudaMemcpy(d_array, h_array, n_bytes, cudaMemcpyHostToDevice)));
	\endcode
	In this code sequence, the memcpy async call may be created before d_array is assigned
	by the malloc call leading to an invalid d_array in the memcpy. Similar race conditions
	can show up with device to host memcpys. These types of race conditions can be very hard to
	debug, so use callAsync() with caution. Primarily, callAsync() should only be used to call
	cuda functions that are asynchronous normally. If you must use callAsync() on a synchronous
	cuda function (one valid use is doing a memcpy to/from 2 GPUs simultaneously), be
	\b absolutely sure to call sync() before attempting to use the results of the call.
*/
void GPUWorker::callAsync(const boost::function< cudaError_t (void) > &func)
	{
	// add the function object to the queue
		{
		mutex::scoped_lock lock(m_mutex);
		m_work_queue.push_back(func);
		m_work_to_do = true;
		}

	// notify the threads there is work to do
	m_cond_work_to_do.notify_one();
	}

/*! Call sync() to synchronize the master thread with the worker thread.
	After a call to sync() returns, it is guarunteed that all previous
	queued calls (via callAsync()) have been called in the worker thread.

	\note Since many CUDA calls are asynchronous, a call to sync() does not
	necessarily mean that all calls have completed on the GPU. To ensure this,
	one must call() cudaThreadSynchronize():
	\code
gpu.call(bind(cudaThreadSynchronize));
	\endcode

	sync() will throw an exception if any of the queued calls resulted in
	a return value not equal to cudaSuccess.
*/
void GPUWorker::sync()
	{
	// wait on the work done signal
	mutex::scoped_lock lock(m_mutex);
	while (m_work_to_do)
		m_cond_work_done.wait(lock);

	// if there was an error
	if (m_last_error != cudaSuccess)
		{
		// build the exception
		runtime_error error("CUDA Error: " + string(cudaGetErrorString(m_last_error)));

		// reset the error value so that it doesn't propagate to continued calls
		m_last_error = cudaSuccess;

		// throw
		throw(error);
		}
	}

/*! \internal
	The worker thread spawns a loop that continusously checks the condition variable
	m_cond_work_to_do. As soon as it is signaled that there is work to do with
	m_work_to_do, it processes all queued calls. After all calls are made,
	m_work_to_do is set to false and m_cond_work_done is notified for anyone
	interested (namely, sync()). During the work, m_exit is also checked. If m_exit
	is true, then the worker thread exits.
*/
void GPUWorker::performWorkLoop()
	{
	bool working = true;

	// temporary queue to ping-pong with the m_work_queue
	// this is done so that jobs can be added to m_work_queue while
	// the worker thread is emptying pong_queue
	deque< boost::function< cudaError_t (void) > > pong_queue;

	while (working)
		{
		// aquire the lock and wait until there is work to do
			{
			mutex::scoped_lock lock(m_mutex);
			while (!m_work_to_do)
				m_cond_work_to_do.wait(lock);

			// check for the exit condition
			if (m_exit)
				working = false;

			// ping-pong the queues
			pong_queue.swap(m_work_queue);
			}

		// track any error that occurs in this queue
		cudaError_t error = cudaSuccess;

		// execute any functions in the queue
		while (!pong_queue.empty())
			{
			cudaError_t tmp_error = pong_queue.front()();

			// update error only if it is cudaSuccess
			// this is done so that any error that occurs will propagate through
			// to the next sync()
			if (error == cudaSuccess)
				error = tmp_error;

			pong_queue.pop_front();
			}

		// reaquire the lock so we can update m_last_error and
		// notify that we are done
			{
			mutex::scoped_lock lock(m_mutex);

			// update m_last_error only if it is cudaSuccess
			// this is done so that any error that occurs will propagate through
			// to the next sync()
			if (m_last_error == cudaSuccess)
				m_last_error = error;

			// notify that we have emptied the queue, but only if the queue is actually empty
			// (call_async() may have added something to the queue while we were executing above)
			if (m_work_queue.empty())
				{
				m_work_to_do = false;
				m_cond_work_done.notify_all();
				}
			}
		}
	}

//#endif

